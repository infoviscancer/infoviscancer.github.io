<!DOCTYPE html>
<html>
<head>
<meta charset='utf-8'>
<link rel="icon" href="images/favicon.png" />
<link rel="stylesheet" type="text/css" href="stylesheets/stylesheet.css" media="screen" />
<title>Stomach cancer gene visualization</title>
</head>

<body>
<a name="anchor0"></a>
<header> <img src="images/dna_header.png" style="display:bock-inline; margin-top:-41px;" />
  <div class="inner" style="display:block-inline; margin-top:-340px;">
    <h1>Stomach cancer gene visualization</h1>
    <h2>Progetto finale per il corso di "Visualizzazione delle Informazioni"</h2>
    <a href="index.html" class="button" id="buttonDataset"><small>il</small>dataset</a> <a href="credits.html" class="button" id="buttonCredits"><small>about</small>credits</a> <a href="clustering.html" class="button" id="buttonVis1"><small>visualizzazioni su</small>clustering</a> <a href="classification.html" class="button" id="buttonVis2"><small>visualizzazioni su</small>classificazione</a> </div>
</header>
<div id="content-wrapper">
  <div class="inner clearfix">
    <section id="main-content">
      <h3><a name="anchor1"><img src="images/img_chapter.png" class="img_chapter"/>The Cancer Genoma Atlas</a></h3>
      <br/>
      <p> <a href="http://cancergenome.nih.gov/" target="_blank">The Cancer Genome Atlas</a> (TCGA) è un’opera globale e coordinata per accelerare la comprensione del cancro attraverso l'applicazione di tecnologie di analisi del genoma, compreso il sequenziamento su larga scala del genoma umano.
        <center>
          <img src="images/tcga_banner.jpg" width="664"><font style="font-style:italic; font-size:12px;">Figura 1: TCGA logo </font>
        </center>
        <br/>
        Offre una piattaforma gratuita che consente di ricercare e scaricare al link <a href="https://tcga-data.nci.nih.gov/tcga/tcgaHome2.jsp" target="_blank">https://tcga-data.nci.nih.gov/tcga/tcgaHome2.jsp</a> interi dataset contenenti informazioni cliniche utili per analisi genomiche, rispettando la privacy dei pazienti. <br/>
        <br/>
        <center>
          <img src="images/tcga2.jpg" width="664"> <font style="font-style:italic; font-size:12px;">Figura 2: TCGA Data Portal Overview </font>
        </center><br/><br/>
        <a href="#anchor0">Back on top.</a>
      </p>
      <br/>
      <h3><a name="anchor2"><img src="images/img_chapter.png" class="img_chapter"/>Descrizione del dataset</a></h3>
      <br/>
      <p> Per lo svolgimento del progetto è stato preso in considerazione il dataset del TCGA relativo all’adenocarcinoma allo stomaco costituito da &#126;271 file di tipo <font style="font-style:italic">gene.quantification.txt</font> (dimensione totale = 330 MB).<br/>
        Ogni file esaminato si riferisce ad uno specifico paziente ed è stato generato applicando la tecnica del RNA-Sequencing, una metodologia per l’analisi del trascrittoma (ovvero l’insieme dei trascritti di RNA che caratterizzano un dato stadio di sviluppo di una cellula). Ciascun file contiene quindi, la lista dei geni del paziente (in media &#126;24000) e per ognuno di essi il valore del RPKM (Reads Per Kilobase per Million mapped reads), oltre ad altre informazioni.<br/>
        Il valore RPKM rappresenta una misura dell’espressione genica ricavata con metodi di normalizzazione applicati nella tecnica di sequenziamento del RNA. <br/>
        <center>
          <img src="images/dataset_description1.jpg" width="664"> <font style="font-style:italic; font-size:12px;">Figura 3: a sinistra viene mostrata una porzione del dataset STAD contenente file gene.quantification.txt.  A destra un file gene.quantification.txt con l’elenco dei geni e i valori di RPKM ad essi associati. </font>
        </center>
        <br/>
        [<a href="doc/TCGA-B7-5816-01A-21R-1602-13.gene.quantification.txt" target="_blank">Example file  gene.quantification.txt</a>] <br/>
        <br/>
        Tutti i nomi dei file presenti nei dataset si uniformano ad un particolare standard (barcode); è stato quindi possibile estrarre da essi il codice identificativo del paziente e la codifica della classe di appartenenza.<br/>
        La figura che segue mostra il barcode per la nomenclatura dei file. <br/>
        <center>
          <img src="images/tcga4.jpg" width="664"> <font style="font-style:italic; font-size:12px;">Figura 4: barcode </font>
        </center>
        <br/>
        Come si nota, il barcode è una composizione di una collezione di identificatori. Ai fini del progetto sono stati presi in considerazione:
      <ul>
        <li>Il Participant, identificativo del paziente</li>
        <li>Il Vial, identificativo dell’ordine del campione in una sequenza di campioni. Assume valori compresi tra A e Z.</li>
        <li>Il Sample, identificativo del tipo di campione esaminato.</li>
      </ul>
      <br/>
      Il Sample può assumere diversi valori:
      <ul>
        <li>da 01 a 09, identificano il tipo Tumoral</li>
        <li>da 10 a 19, identificano il tipo Normal</li>
        <li>da 20 a 29, identificano il tipo Control</li>
      </ul>
      <br/><br/>
        <a href="#anchor0">Back on top.</a>
      </p>
      <h3><a name="anchor3"><img src="images/img_chapter.png" class="img_chapter"/>Estrazione dei dati</a></h3>
      <br/>
      <p> Per estrarre le informazioni di interesse si è proceduto alla creazione di un Job Map-Reduce utilizzando  il framework Apache Hadoop.<br/>
      <ul>
        <li> <b>Fase di Map</b><br/>
          Nella fase di Map, a partire dal nome del file di ogni paziente, vengono estratti il Participant, il Sample e il Vial che, insieme, andranno a costituire le “key” del mapper.<br/>
          Per ogni file vengono inoltre estratti i nomi dei geni e il valore del RPKM ad essi associato che, combinati insieme attraverso un separatore (il carattere “$”), andranno a rappresentare i “value” del mapper.<br/>
          Da questa prima fase si ottengono quindi coppie chiave – valore del tipo:<br/>
          <br/>
          <center>
            [Participant(SampleVial), gene$RPKM]
          </center>
        </li>
        <br/>
        <li> <b>Fase di Reduce</b><br/>
          La fase di Reduce prende in input l’output del mapper raggruppato per chiave, ovvero coppie chiave-valore nelle quali la chiave è costituita dalla stringa Participant(sampleVial) e il valore è una lista di gene$RPKM associati alla chiave.<br/>
          In questa fase inoltre viene stabilita la forma che avrà l’output del job sia nel File-System di Hadoop che in un file con estensione csv. </li>
        <br/>
        <li> <b>Output generato</b><br/>
          E’ stato previsto un solo tipo di output in forma matriciale contenente il nome dei geni sulle colonne e l’identificativo dei partecipanti nelle righe. <br/>
          <center>
            <img src="images/tcga5.jpg" width="664"> <font style="font-style:italic; font-size:12px;">Figura 5: output-matrice originale </font>
          </center>
          <br/>
          Come evidenziato in Figura 5, l’output sui file csv per la matrice originale ha una struttura del tipo: PARTICIPANT ID | CLASS ID | GENE-1|…|GENE-n|CLASS.<br/>
          <br/>
          <ul>
            <li>PARTICIPANT ID: è l’identificativo del paziente (= Participant nel barcode). </li>
            <li>CLASS ID: rappresenta la classe di appartenenza del paziente codificata (Tumoral, Normal, Control)  e il Sample e il Vial ad esso associati.</li>
            <li>GENE-1|…|GENE-n: identificatori delle colonne sono i nomi dei geni, per ciascun gene e ciascun paziente si ha, associato, il valore RPKM.</li>
            <li>CLASS: rappresenta la classe di appartenenza del paziente (Tumoral, Normal, Control), è una codifica del Sample.</li>
          </ul>
          Gli attributi CLASS e CLASS ID sono stati introdotti nelle matrici ai fini dell’analisi dei dati. Il CLASS ID, come accennato, è costituito dal Sample e dalla relativa codifica (Es: Tumoral (01A)) e viene preso in considerazione per analisi di maggior dettaglio. L’attributo CLASS invece è una forma di ridondanza della codifica del Sample ed è stato introdotto per generalizzare il campo di analisi. </li>
        <br/>
        <li> <b>Dettagli di sviluppo</b><br/>
          Come precedentemente accennato, la generazione dell’output sul file csv, avviene direttamente nella fase di Reduce, andando ad inserire l’intestazione della matrice (“intestazione”) e i relativi dati (“stringa”).
          La figura 6 mostra la porzione di codice per la creazione dell’output. <br/>
          <br/>
          <center>
            <img src="images/tcga6.jpg" width="664"> <font style="font-style:italic; font-size:12px;">Figura 6: porzione di codice relativo alla generazione dell’output </font>
          </center>
        </li>
      </ul>
      <br/><br/>
        <a href="#anchor0">Back on top.</a>
      </p>
      <h3><a name="anchor4"><img src="images/img_chapter.png" class="img_chapter"/>Analisi dei dati</a></h3>
      <br/>
      <p> L’analisi dei dati è stata condotta utilizzando il software WEKA, acronimo di "Waikato Environment for Knowledge Analysis", che fornisce un insieme di algoritmi per  l'apprendimento automatico e l’estrazione di conoscenza dai dati (attività di machine learning e data mining). <br/>
      <ul>
        <li> <b>Classificazione</b><br/>
          <br/>
          La classificazione ha come obbiettivo l’estrazione di modelli che descrivono classi di dati per predire valori categorici o continui. La costruzione del modello viene generalmente fatta a partire da un insieme predeterminato di classi o concetti (Training set).<br/>
          Per effettuare la classificazione con Weka sono stati utilizzati alberi decisionali “Trees” (in questo caso l’algoritmo J48), utilizzando come Test Options la Cross-validation. In questo modo i record vengono suddivisi in un determinato numero di folds (nel nostro caso 10) e ogni fold, a turno, funge da validation set. Alla fine dell’analisi vengono calcolati diversi valori tra i quali il mean square error o errore quadratico medio che misura la discrepanza quadratica media fra i valori dei dati osservati ed i valori dei dati stimati, il numero e la percentuale delle istanze classificate correttamente e non e l’accuracy espressa in termini di Precision, Recall e F-Measure.<br/>
          <br/>
          L’output della classificazione, a meno di componenti opzionali, è così costituito:<br/>
          <br/>
          <ul>
            <li><b>Run information</b>: informazioni relative al programma di apprendimento, al nome della relazione, al numero di istanze e di attributi e alle modalità di prova che sono state coinvolte nel processo.</li>
            <li><b>Classifier model (full training set)</b>: il testo del modello di classificazione che è stato prodotto sull’intero training set.
            <li><b>Summary</b>: un elenco di statistiche che riassume come il classificatore è stato in grado di predire la classe delle istanze del Test set, tra le quali l’ errore quadratico medio e la correttezza delle istanze classificate.</li>
            <li><b>Detailed Accuracy By Class</b>: informazioni dettagliate sulla precisione di ogni classe di predizione (Precision, Recall, FMeasure).</li>
            <li><b>Confusion Matrix</b>: mostra il numero di casi che sono stati assegnati a ciascuna classe. Sulla sua diagonale principale si individuano i valori classificati correttamente, mentre nelle restanti celle si individuano gli errori di predizione.</li>
          </ul>
          <br/>
          Di seguito si riportano come esempio porzioni di output ottenute applicando “Tree” al dataset STAD.<br/>
          In blu vengono messe in risalto le varie componenti dell’output della classificazione, in rosso i risultati delle analisi. <br/>
          <br/>
          <center>
            <img src="images/tcga7.jpg" width="664"> <font style="font-style:italic; font-size:12px;">Figura 7: porzione di output dell’analisi ottenuta con l’algoritmo J48 </font>
          </center>
          <br/>
          Nel riquadro evidenziato in rosso (Figura 7) si nota il testo del modello di classificazione prodotto sull’intero training set, nel Summary sono riportate invece il numero di istanze classificate correttamente e non e l’errore quadratico medio.<br/>
          L’alta percentuale di istanze classificate correttamente dimostra la validità e la bontà del modello di classificazione ottenuto mediante l’applicazione dell’algoritmo J48.<br/>
          Nella figura che segue vengono messe in risalto l’accuracy del modello di classificazione per le due classi del dataset (Tumoral e Normal) e la relativa matrice di confusione.<br/>
          Attraverso la diagonale principale della matrice di confusione possiamo ricavare il numero delle istanze classificate correttamente.<br/>
          Analizzando i valori di Precision, Recall e F-Measure abbiamo la conferma della bontà del modello di classificazione; tutti e tre i valori sono infatti prossimi all’unità. <br/>
          <br/>
          <center>
            <img src="images/tcga8.jpg" width="664"> <font style="font-style:italic; font-size:12px;">Figura 8: porzione di output dell’analisi ottenuta con l’algoritmo J48 </font>
          </center>
          <br/>
          Nella figura 9 viene messa in evidenza la sezione dell’output <b>Run Information</b>, in essa abbiamo indicazioni dell’algoritmo di classificazione applicato (in questo caso J48), del numero di istanze e del numero di attributi analizzati, del <font style="font-style:italic;">Test Option</font> (cross-validation) e del numero di <font style="font-style:italic;">fold</font> scelte. <br/>
          <br/>
          <center>
            <img src="images/tcga9.jpg" width="664"> <font style="font-style:italic; font-size:12px;">Figura 9: porzione di output dell’analisi ottenuta con l’algoritmo J48 </font>
          </center>
          <br/>
          La figura 10 mostra la corrispondenza tra il numero di istanze classificate correttamente riportato nel Summary e lo stesso valore ricavabile dalla diagonale principale della matrice di confusione. In questo caso il modello di classificazione è stato ricavato dall’applicazione dell’algoritmo J48. <br/>
          <br/>
          <center>
            <img src="images/tcga10.jpg" width="664"> <font style="font-style:italic; font-size:12px;">Figura 10: porzione di output dell’analisi ottenuta con l’algoritmo Tree J48 </font>
          </center>
        </li><br/>
        <li> <b>Clustering</b><br/>
          <br/>
          Le tecniche di clustering si applicano per suddividere un insieme di istanze in gruppi che riflettano qualche meccanismo o caratteristica naturale del dominio di appartenenza delle istanze stesse. Queste proprietà fanno sì che delle istanze siano accomunate da una “somiglianza” più forte rispetto agli altri dati della collezione.<br/>
          Lo scopo di un algoritmo di clustering è quello di suddividere un insieme di dati in gruppi che siano quanto più possibile coerenti fra loro e allo stesso tempo diversi l’uno dall’altro (l’alta similarità intra-cluster e la bassa similarità inter-cluster).<br/>
          Il clustering rappresenta la forma più comune di apprendimento non supervisionato (nessun uso di esperti umani per assegnare le istanze alle classi). L’input chiave di un algoritmo di questo tipo è dato dalla misura della distanza che viene utilizzata per suddividere le istanze in gruppi.<br/>
          Per effettuare l’analisi di cluster è stato applicato su ogni dataset l’algoritmo K-Means, il più importante algoritmo di <font style="font-style:italic;">Flat clustering</font> (crea un insieme di cluster piatto, senza una struttura gerarchica che metta in relazione i cluster l’un l’altro). Obbiettivo di K-Means è quello di minimizzare il valor medio del quadrato della distanza euclidea dei documenti dal centro del cluster a cui sono stati assegnati.<br/>
          Il centro di un cluster è definito come la media di tutti i documenti presenti nel cluster (centroide).<br/>
          Per la valutazione dei cluster, come accaduto per la classificazione, è stato utilizzato l’attributo CLASS.<br/>
          Di seguito si riporta una porzione della schermata di output del clustering sul dataset STAD- Stomach_cancer e le relative visualizzazioni dei cluster.
          All’interno della sezione Run Information vengono evidenziati, in rosso, l’algoritmo di clustering applicato e il numero di istanze e di attributi valutati.<br/>
          Nella sezione KMeans si trovano informazioni relative al numero di iterazioni dell’algoritmo e alla somma dell’errore quadratico, seguite dalla lista degli attributi analizzati, dal numero e dal valore delle istanze totali e delle istanze per ciascun cluster creato (in questo caso 2, uno per le istanze di tipo Normal, l’altro per le istanze di tipo Tumoral, come messo in evidenza nella figura 13). <br/>
          <br/>
          <center>
            <img src="images/tcga11.jpg" width="664"> <font style="font-style:italic; font-size:12px;">Figura 11: porzione di output dell’analisi ottenuta con l’algoritmo Simple K-Means </font>
          </center>
          <br/>
          <br/>
          <br/>
          <center>
            <img src="images/tcga12.jpg" width="664"> <font style="font-style:italic; font-size:12px;">Figura 12: porzione di output dell’analisi ottenuta con l’algoritmo Simple K-Means </font>
          </center>
          <br/>
          Questa seconda porzione di output oltre ad indicare il numero e la percentuale di istanze per cluster, il class attribute e la tipologia di istanze appartenenti a ciascun cluster, mette in evidenza anche il numero e la percentuale delle istanze clusterizzate in modo errato, in questo caso circa il 28% (76/210) un valore non molto trascurabile, indice di un modello di clustering non proprio perfetto e accurato come lo erano stati i modelli di classificazione. </li>
      </ul>
      <br/><br/>
        <a href="#anchor0">Back on top.</a>
      </p>
    </section>
    <aside id="sidebar">
      <ul>
        <li><a href="#anchor1">TCGA</a></li>
        <li><a href="#anchor2">Descrizione del dataset</a></li>
        <li><a href="#anchor3">Estrazione dei dati</a></li>
         <li><a href="#anchor4">Analisi dei dati</a></li>
      </ul>
    </aside>
  </div>
</div>
<div style="text-align: center">
  <footer> <span style="font-weight: bold;">Stefano Calcaterra, Federico Mione - Information Visualization Final Project, A.A. 2013-2014</span><br/>
  </footer>
</div>
</body>
</html>
